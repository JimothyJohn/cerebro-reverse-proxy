![cerebro](docs/cerebro.png)
# Cerebro (Reverese proxe) 

This repository provides a setup for deploying a reverse proxy for the Replicate API endpoint of Microsoft's multi-modal Phi-3.5-vision-instruct model. The goal is to create an efficient cloud deployment, making it easier, faster, and more accessible to utilize vision perception models for niche use cases.

**Note:** The code in this repository is AI-generated by GPT-4; please review and test thoroughly.

## Features

- **OpenAI API Compatible:** The API endpoint follows OpenAI's API standards for familiarity and ease of use.
- **API Key Authentication:** Users are required to provide an API key in their requests.
- **Error Handling:** Provides clear error messages consistent with OpenAI's API error format.
- **Easy Deployment:** Configurations are provided for quick setup using AWS SAM.
- **Scalable:** Designed for enterprise users seeking insights from images with structured outputs.

## Getting Started

### Prerequisites

- AWS Account with permissions to deploy Lambda functions and API Gateway
- AWS SAM CLI installed
- Python 3.11 installed
- Docker installed (for containerization)
- Replicate API Token (stored in AWS Secrets Manager as `ReplicateApiToken`)

### Setup Instructions

1. **Clone the Repository**

   ```bash
   git clone https://github.com/YourUsername/cerebro.git
   cd cerebro
Install Dependencies
```bash
./Quickstart.sh
```

The script will:

- Check for required dependencies (docker, sam, pip).

- Create a virtual environment and install Python dependencies.

- Format the code using black.

- Build and deploy the AWS SAM application.

- Configure AWS Credentials

- Ensure your AWS credentials are configured for deployment.

```bash
aws configure
```

Set the Replicate API Token
Store your Replicate API token in AWS Secrets Manager with the name ReplicateApiToken.

```bash
aws secretsmanager create-secret --name ReplicateApiToken --secret-string "your_replicate_api_token"
```

Usage

After deployment, you can make POST requests to the API Gateway endpoint to interact with the model.

Request Format
Endpoint:

```bash
POST https://your-api-endpoint/Prod/v1/completions
Headers:
Content-Type: application/json
Authorization: Bearer YOUR_API_KEY
Body:
```

```json
{
  "prompt": "Describe the image.",
  "image_urls": "https://example.com/image.jpg",
  "max_tokens": 1000,
  "temperature": 0.7,
  "do_sample": true
}
```

Response Format
The response follows OpenAI's API completion format.

```json
{
  "id": "prediction-id",
  "object": "text_completion",
  "created": 1625159073,
  "model": "cerebro-phi3.5-vision-instruct",
  "choices": [
    {
      "text": "The image shows...",
      "index": 0,
      "logprobs": null,
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 5,
    "completion_tokens": 50,
    "total_tokens": 55
  }
}
```

### Notes

- API Key Authentication: You must provide an API key in the Authorization header. The format should be Bearer YOUR_API_KEY.

- AI-Generated Code: Most of the code in this repository is AI-generated and should be reviewed for correctness and compatibility.

- Model Updates: Ensure that the REPLICATE_MODEL_VERSION environment variable is set to the latest version hash if updates occur.

### Contributing

Contributions are welcome! Please submit a pull request or open an issue for any changes or suggestions.

### License

This project is licensed under the MIT License.

vbnet
Copy code

---

# Conclusion

I've updated the code and documentation to reflect your requirements:

- The API now adheres to OpenAI's API standards.
- API key authentication is implemented, requiring users to provide an API key.
- Error handling provides specific messages when the API key is missing or invalid.
- Unit tests have been expanded to cover the scenarios you've specified.
- The API is kept as simple as possible, following OpenAPI standards.

Please review the updated code and let me know if you need further adjustments or clarifications.
